{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "import pandas as pd\n",
    "import flair.datasets as datasets\n",
    "\n",
    "from tqdm import tqdm\n",
    "from gensim.models import KeyedVectors\n",
    "from flair.embeddings import BytePairEmbeddings\n",
    "from flair.embeddings import DocumentPoolEmbeddings, SentenceTransformerDocumentEmbeddings\n",
    "from wikipedia2vec import Wikipedia2Vec\n",
    "from src.models.base import Base\n",
    "from src.models.flair import BaseFlair\n",
    "from src.models.wiki2vec import BaseWiki2Vec\n",
    "from data.utils import getCandidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_PATH = \"./embeddings/\"\n",
    "aida = datasets.NEL_ENGLISH_AIDA()\n",
    "entity_desc = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions_tags = []\n",
    "doc = 1162\n",
    "for i in aida.test:\n",
    "\tcontext = i.to_plain_string()\n",
    "\tif context != '-DOCSTART-':\n",
    "\t\tmentions_tags += [[j.text, j.tag, context, doc] for j in i.get_spans()]\n",
    "\telse:\n",
    "\t\tdoc += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_desc(entity):\n",
    "\ttry:\n",
    "\t\treturn entity_desc[entity_desc['entity'] == entity]['description'].values[0]\n",
    "\texcept:\n",
    "\t\treturn ''\n",
    "\n",
    "def get_candidates(mention, doc):\n",
    "\tdf = getCandidates(doc, mention=mention)\n",
    "\tres = [i.split('/')[-1] for i in df['url'].values]\n",
    "\tcands = []\n",
    "\tfor i in res:\n",
    "\t\tdesc = get_entity_desc(i)\n",
    "\t\tif desc != '':\n",
    "\t\t\tcands.append([i, desc])\n",
    "\treturn cands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing base NED model using various types of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_batch(model, batch):\n",
    "\tpreds = []\n",
    "\tfor mention, tag, context, doc in tqdm(batch):\n",
    "\t\tcands = get_candidates(mention, doc)\n",
    "\t\t# Check the tag is a valid entity and is present in the candidate set\n",
    "\t\tif tag in [i[0] for i in cands]:\n",
    "\t\t\tpred_tag, conf = model.link(mention, context, candidates=cands)\n",
    "\t\t\tpreds.append([mention, tag, pred_tag, conf])\n",
    "\treturn preds\n",
    "\n",
    "\n",
    "def batch(l, n):\n",
    "\tfor i in range(0, len(l), n): \n",
    "\t\tyield l[i:i + n]\n",
    "\n",
    "\n",
    "def test(emb, model, docEmb=None, batchSize=0, saveAs=None):\n",
    "\tpreds = []\n",
    "\tbatches = list(batch(mentions_tags, batchSize)) if batchSize != 0 else [mentions_tags]\n",
    "\tfor i in batches:\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tned = model(docEmb(emb)) if docEmb is not None else model(emb)\n",
    "\t\t\tpreds += test_batch(ned, i)\n",
    "\t\t\tclear_gpu_cache([ned, model, docEmb])\n",
    "\n",
    "\tres = pd.DataFrame(preds, columns=['mention', 'tag', 'predicted', 'confidence'])\n",
    "\tif saveAs is not None:\n",
    "\t\tres.to_csv(saveAs, index=False)\n",
    "\tif res.shape[0] > 0:\n",
    "\t\tacc = (res[res['tag'] == res['predicted']].shape[0]/res.shape[0])*100\n",
    "\telse:\n",
    "\t\tacc = 0\n",
    "\tprint (\"Accuracy: \", acc)\n",
    "\n",
    "\n",
    "def clear_gpu_cache(objects):\n",
    "\tfor i in objects: i = None\n",
    "\tgc.collect()\n",
    "\ttorch.cuda.empty_cache()\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec Google News 300d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = KeyedVectors.load(EMB_PATH + 'word2vec-google-news-300')\n",
    "test(word2vec, Base, saveAs='./results/base_word2vec.csv')\n",
    "# Cased : 52.37 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove Wiki-Gigaword 300d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = KeyedVectors.load(EMB_PATH + 'glove-wiki-gigaword-300')\n",
    "test(glove,Base, saveAs='./results/base_glove.csv')\n",
    "# Cased : 51.97 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Byte-Pair, 300d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "byte_pair = BytePairEmbeddings('en', dim=300, syllables=200000)\n",
    "bp_doc_emb = DocumentPoolEmbeddings([byte_pair], fine_tune_mode='nonlinear')\n",
    "test(bp_doc_emb, BaseFlair, saveAs='./results/base_byte_pair.csv')\n",
    "# Cased : 51.00 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText Wiki-News Subword 300d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftext = KeyedVectors.load(EMB_PATH + 'fasttext-wiki-news-subwords-300')\n",
    "test(ftext, Base, saveAs='./results/base_fasttext.csv')\n",
    "# Cased : 39.44 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(\n",
    "\t'roberta-base',\n",
    "\tBaseFlair,\n",
    "\tdocEmb=SentenceTransformerDocumentEmbeddings,\n",
    "\tbatchSize=300, \n",
    "\tsaveAs='./results/base_roberta.csv')\n",
    "# Cased : 34.92 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikipedia2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki2vec = Wikipedia2Vec.load(EMB_PATH + 'wiki2vec_w10_100d.pkl')\n",
    "test(wiki2vec, BaseWiki2Vec, saveAs='./results/base_wiki2vec.csv')\n",
    "# Cased : 62.06%"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d3c83394ae731fac5cbf34b5abe7ebcd59fb96b846f104eed2689aeb9dd8ae81"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('NED-using-KG': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
